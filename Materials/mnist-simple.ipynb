{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FN = 'mnist-simple'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook works with Keras version 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we:\n",
    "* train a on MNIST in which the training labels are scrambled by a fixed permutation 46% of the time\n",
    "* The baseline 3 layer MLP model gives an accuracy of 74% on MNIST test set which was not scrambled\n",
    "* The confusion matrix of the noisy training data is computed\n",
    "* We then add a customized Keras layer ([Channel](./channel.py)) to model the noise. This layer is initialized with the log of the confusion matrix (`channel_weights`):\n",
    "```python\n",
    "channeled_output = Channel(name='channel',weights=[channel_weights])(baseline_output)\n",
    "```\n",
    "* We continue training on the new output (`channeled_output`)\n",
    "* The baseline output (`baseline_output`) has now an accuracy of 98%.\n",
    "\n",
    "For more information see the description of the [simple noise adaptation layer in the paper](https://openreview.net/forum?id=H12GRgcxg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import random\n",
    "seed = 42\n",
    "np.random.seed(seed)  # for reproducibility\n",
    "random.seed(seed)\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in case you dont have a GPU\n",
    "import os\n",
    "os.environ['THEANO_FLAGS'] = 'device=cpu,floatX=float32'  # Use CPU on Theano\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''  # Disable GPU usage on tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 10 # number of categories we classify. MNIST is 10 digits\n",
    "# input image dimensions. In CNN we think we have a \"color\" image with 1 channel of color.\n",
    "# in MLP with flatten the pixels to img_rows*img_cols\n",
    "img_color, img_rows, img_cols = 1, 28, 28\n",
    "img_size = img_color*img_rows*img_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST training data set label distribution [5923 6742 5958 6131 5842 5421 5918 6265 5851 5949]\n",
      "test distribution [ 980 1135 1032 1010  982  892  958 1028  974 1009]\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "# keras has a built in tool that download the MNIST data set for you to `~/.keras/datasets/`\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print('MNIST training data set label distribution', np.bincount(y_train))\n",
    "print('test distribution', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 784)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], img_size)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_size)\n",
    "    \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.\n",
    "X_test /= 255.\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## noisy labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NOISE_LEVEL=0.46  # what part of training labels are permuted\n",
    "perm = np.array([7, 9, 0, 4, 2, 1, 3, 5, 6, 8])  # noise permutation (from Reed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise = perm[y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace some of the training labels with permuted (noise) labels.\n",
    "# make sure each categories receive an equal amount of noise\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "_, noise_idx = next(iter(StratifiedShuffleSplit(n_splits=1,\n",
    "                                                test_size=NOISE_LEVEL,\n",
    "                                                random_state=seed).split(X_train,y_train)))\n",
    "y_train_noise = y_train.copy()\n",
    "y_train_noise[noise_idx] = noise[noise_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "actual noise level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45999999999999996"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1. - np.mean(y_train_noise == y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split training data to training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# break the training set to 10% validation which we will use for early stopping.\n",
    "train_idx, val_idx = next(iter(\n",
    "        StratifiedShuffleSplit(n_splits=1, test_size=0.1,\n",
    "                               random_state=seed).split(X_train, y_train_noise)))\n",
    "X_train_train = X_train[train_idx]\n",
    "y_train_train = y_train_noise[train_idx]\n",
    "X_train_val = X_train[val_idx]\n",
    "y_train_val = y_train_noise[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline model\n",
    "We use the `Sequential` model from keras\n",
    "[mlp example](https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py)\n",
    "as a single layer which computes the last hidden layer which we then use to\n",
    "compute the baseline and as an input to the channel matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nhiddens = [500, 300]\n",
    "DROPOUT=0.5\n",
    "opt='adam'\n",
    "batch_size = 256\n",
    "patience = 4  # Early stopping patience\n",
    "epochs = 40  # number of epochs to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "hidden_layers = Sequential(name='hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation\n",
    "for i, nhidden in enumerate(nhiddens):\n",
    "    hidden_layers.add(Dense(nhidden,\n",
    "                            input_shape=(img_size,) if i == 0 else []))\n",
    "    hidden_layers.add(Activation('relu'))\n",
    "    hidden_layers.add(Dropout(DROPOUT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "train_inputs = Input(shape=(img_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_hidden = hidden_layers(train_inputs)\n",
    "baseline_output = Dense(nb_classes, activation='softmax', name='baseline')(last_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brucelau/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "model = Model(input=train_inputs, output=baseline_output)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline model performance evaluation before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval(model,y_test=y_test):\n",
    "    return dict(zip(model.metrics_names,model.evaluate(X_test,y_test, verbose=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.1065, 'loss': 2.3589877407073976}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brucelau/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/40\n",
      "54000/54000 [==============================] - 2s 41us/step - loss: 1.2585 - acc: 0.4248 - val_loss: 0.9060 - val_acc: 0.4932\n",
      "Epoch 2/40\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.9398 - acc: 0.4840 - val_loss: 0.8394 - val_acc: 0.4875\n",
      "Epoch 3/40\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.8770 - acc: 0.4959 - val_loss: 0.8165 - val_acc: 0.4943\n",
      "Epoch 4/40\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.8452 - acc: 0.4977 - val_loss: 0.7939 - val_acc: 0.4993\n",
      "Epoch 5/40\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.8207 - acc: 0.5090 - val_loss: 0.7882 - val_acc: 0.5072\n",
      "Epoch 6/40\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.8071 - acc: 0.5087 - val_loss: 0.7831 - val_acc: 0.5163\n",
      "Epoch 7/40\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.7961 - acc: 0.5148 - val_loss: 0.7730 - val_acc: 0.5203\n",
      "Epoch 8/40\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.7853 - acc: 0.5176 - val_loss: 0.7673 - val_acc: 0.5160\n",
      "Epoch 9/40\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.7739 - acc: 0.5208 - val_loss: 0.7674 - val_acc: 0.5078\n",
      "Epoch 10/40\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.7714 - acc: 0.5204 - val_loss: 0.7613 - val_acc: 0.5043\n",
      "Epoch 11/40\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.7628 - acc: 0.5252 - val_loss: 0.7639 - val_acc: 0.5048\n",
      "Epoch 12/40\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.7592 - acc: 0.5254 - val_loss: 0.7660 - val_acc: 0.5038\n",
      "Epoch 13/40\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.7551 - acc: 0.5268 - val_loss: 0.7651 - val_acc: 0.5208\n",
      "Epoch 14/40\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.7514 - acc: 0.5274 - val_loss: 0.7656 - val_acc: 0.5007\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "train_res = model.fit(X_train_train,\n",
    "                      y_train_train,\n",
    "                      batch_size=batch_size,\n",
    "                      nb_epoch=epochs,\n",
    "                      verbose=verbose,\n",
    "                      validation_data=(X_train_val,\n",
    "                                       y_train_val),\n",
    "                      callbacks=\n",
    "                      [EarlyStopping(patience=patience,mode='min',\n",
    "                                     verbose=verbose)]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# eval(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build confusion matrix (prediction,noisy_label)\n",
    "ybaseline_predict = model.predict(X_train,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ybaseline_predict = np.argmax(ybaseline_predict, axis=-1)\n",
    "ybaseline_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline_confusion = np.zeros((nb_classes, nb_classes))\n",
    "for n, p in zip(y_train_noise, ybaseline_predict):\n",
    "    baseline_confusion[p, n] += 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npRU2VwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f79b901ff60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# perm_bias_weights.astype(int)\n",
    "plt.pcolor(baseline_confusion)\n",
    "plt.ylabel('true labels')\n",
    "plt.xlabel('baseline labels')\n",
    "plt.title('baseline confusion matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple channel model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ignore baseline loss in training\n",
    "BETA = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# channel_weights = baseline_confusion.copy()\n",
    "# channel_weights /= channel_weights.sum(axis=1, keepdims=True)\n",
    "# # perm_bias_weights[prediction,noisy_label] = log(P(noisy_label|prediction))\n",
    "# channel_weights = np.log(channel_weights + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you dont have a pre-trained baseline model then use this\n",
    "channel_weights = (\n",
    "    np.array([[np.log(1. - NOISE_LEVEL)\n",
    "                        if i == j else\n",
    "                        np.log(0.46 / (nb_classes - 1.))\n",
    "                        for j in range(nb_classes)] for i in\n",
    "              range(nb_classes)])\n",
    "    + 0.01 * np.random.random((nb_classes, nb_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from channel import Channel\n",
    "channeled_output = Channel(name='channel',weights=[channel_weights])(baseline_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_model = Model(inputs=train_inputs, outputs=[channeled_output, baseline_output])\n",
    "simple_model.compile(loss='sparse_categorical_crossentropy',loss_weights=[1.-BETA, BETA],\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/40\n",
      "54000/54000 [==============================] - 2s 42us/step - loss: 1.1868 - channel_loss: 1.1868 - baseline_loss: 0.7578 - channel_acc: 0.5295 - baseline_acc: 0.5296 - val_loss: 1.1296 - val_channel_loss: 1.1296 - val_baseline_loss: 0.7656 - val_channel_acc: 0.5092 - val_baseline_acc: 0.5125\n",
      "Epoch 2/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 1.0745 - channel_loss: 1.0745 - baseline_loss: 0.7520 - channel_acc: 0.5320 - baseline_acc: 0.5325 - val_loss: 1.0383 - val_channel_loss: 1.0383 - val_baseline_loss: 0.7685 - val_channel_acc: 0.5083 - val_baseline_acc: 0.5090\n",
      "Epoch 3/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.9956 - channel_loss: 0.9956 - baseline_loss: 0.7504 - channel_acc: 0.5305 - baseline_acc: 0.5311 - val_loss: 0.9722 - val_channel_loss: 0.9722 - val_baseline_loss: 0.7663 - val_channel_acc: 0.5038 - val_baseline_acc: 0.5062\n",
      "Epoch 4/40\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.9364 - channel_loss: 0.9364 - baseline_loss: 0.7478 - channel_acc: 0.5371 - baseline_acc: 0.5376 - val_loss: 0.9265 - val_channel_loss: 0.9265 - val_baseline_loss: 0.7688 - val_channel_acc: 0.5027 - val_baseline_acc: 0.5030\n",
      "Epoch 5/40\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.8943 - channel_loss: 0.8943 - baseline_loss: 0.7468 - channel_acc: 0.5376 - baseline_acc: 0.5382 - val_loss: 0.8938 - val_channel_loss: 0.8938 - val_baseline_loss: 0.7729 - val_channel_acc: 0.5057 - val_baseline_acc: 0.5058\n",
      "Epoch 6/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.8637 - channel_loss: 0.8637 - baseline_loss: 0.7447 - channel_acc: 0.5345 - baseline_acc: 0.5348 - val_loss: 0.8639 - val_channel_loss: 0.8639 - val_baseline_loss: 0.7650 - val_channel_acc: 0.5055 - val_baseline_acc: 0.5065\n",
      "Epoch 7/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.8391 - channel_loss: 0.8391 - baseline_loss: 0.7431 - channel_acc: 0.5401 - baseline_acc: 0.5398 - val_loss: 0.8384 - val_channel_loss: 0.8384 - val_baseline_loss: 0.7600 - val_channel_acc: 0.5247 - val_baseline_acc: 0.5242\n",
      "Epoch 8/40\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.8134 - channel_loss: 0.8134 - baseline_loss: 0.7331 - channel_acc: 0.5434 - baseline_acc: 0.5435 - val_loss: 0.8284 - val_channel_loss: 0.8284 - val_baseline_loss: 0.7650 - val_channel_acc: 0.5167 - val_baseline_acc: 0.5180\n",
      "Epoch 9/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.8008 - channel_loss: 0.8008 - baseline_loss: 0.7350 - channel_acc: 0.5450 - baseline_acc: 0.5454 - val_loss: 0.8177 - val_channel_loss: 0.8177 - val_baseline_loss: 0.7684 - val_channel_acc: 0.5110 - val_baseline_acc: 0.5102\n",
      "Epoch 10/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.7883 - channel_loss: 0.7883 - baseline_loss: 0.7329 - channel_acc: 0.5414 - baseline_acc: 0.5415 - val_loss: 0.8061 - val_channel_loss: 0.8061 - val_baseline_loss: 0.7633 - val_channel_acc: 0.5163 - val_baseline_acc: 0.5157\n",
      "Epoch 11/40\n",
      "54000/54000 [==============================] - 2s 41us/step - loss: 0.7791 - channel_loss: 0.7791 - baseline_loss: 0.7325 - channel_acc: 0.5473 - baseline_acc: 0.5472 - val_loss: 0.8022 - val_channel_loss: 0.8022 - val_baseline_loss: 0.7673 - val_channel_acc: 0.5120 - val_baseline_acc: 0.5128\n",
      "Epoch 12/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.7670 - channel_loss: 0.7670 - baseline_loss: 0.7269 - channel_acc: 0.5482 - baseline_acc: 0.5481 - val_loss: 0.7941 - val_channel_loss: 0.7941 - val_baseline_loss: 0.7668 - val_channel_acc: 0.5062 - val_baseline_acc: 0.5060\n",
      "Epoch 13/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.7577 - channel_loss: 0.7577 - baseline_loss: 0.7230 - channel_acc: 0.5513 - baseline_acc: 0.5513 - val_loss: 0.7904 - val_channel_loss: 0.7904 - val_baseline_loss: 0.7657 - val_channel_acc: 0.5107 - val_baseline_acc: 0.5108\n",
      "Epoch 14/40\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.7515 - channel_loss: 0.7515 - baseline_loss: 0.7218 - channel_acc: 0.5513 - baseline_acc: 0.5514 - val_loss: 0.7892 - val_channel_loss: 0.7892 - val_baseline_loss: 0.7682 - val_channel_acc: 0.5128 - val_baseline_acc: 0.5130\n",
      "Epoch 15/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.7482 - channel_loss: 0.7482 - baseline_loss: 0.7222 - channel_acc: 0.5514 - baseline_acc: 0.5513 - val_loss: 0.7831 - val_channel_loss: 0.7831 - val_baseline_loss: 0.7647 - val_channel_acc: 0.5097 - val_baseline_acc: 0.5095\n",
      "Epoch 16/40\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.7436 - channel_loss: 0.7436 - baseline_loss: 0.7212 - channel_acc: 0.5485 - baseline_acc: 0.5486 - val_loss: 0.7776 - val_channel_loss: 0.7776 - val_baseline_loss: 0.7627 - val_channel_acc: 0.5108 - val_baseline_acc: 0.5115\n",
      "Epoch 17/40\n",
      "54000/54000 [==============================] - 2s 42us/step - loss: 0.7392 - channel_loss: 0.7392 - baseline_loss: 0.7197 - channel_acc: 0.5541 - baseline_acc: 0.5539 - val_loss: 0.7829 - val_channel_loss: 0.7829 - val_baseline_loss: 0.7730 - val_channel_acc: 0.5072 - val_baseline_acc: 0.5072\n",
      "Epoch 18/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.7321 - channel_loss: 0.7321 - baseline_loss: 0.7151 - channel_acc: 0.5579 - baseline_acc: 0.5578 - val_loss: 0.7733 - val_channel_loss: 0.7733 - val_baseline_loss: 0.7647 - val_channel_acc: 0.5193 - val_baseline_acc: 0.5185\n",
      "Epoch 19/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.7286 - channel_loss: 0.7286 - baseline_loss: 0.7139 - channel_acc: 0.5606 - baseline_acc: 0.5609 - val_loss: 0.7750 - val_channel_loss: 0.7750 - val_baseline_loss: 0.7674 - val_channel_acc: 0.5040 - val_baseline_acc: 0.5043\n",
      "Epoch 20/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.7264 - channel_loss: 0.7264 - baseline_loss: 0.7132 - channel_acc: 0.5567 - baseline_acc: 0.5566 - val_loss: 0.7748 - val_channel_loss: 0.7748 - val_baseline_loss: 0.7694 - val_channel_acc: 0.5090 - val_baseline_acc: 0.5092\n",
      "Epoch 21/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.7232 - channel_loss: 0.7232 - baseline_loss: 0.7109 - channel_acc: 0.5573 - baseline_acc: 0.5572 - val_loss: 0.7729 - val_channel_loss: 0.7729 - val_baseline_loss: 0.7683 - val_channel_acc: 0.5048 - val_baseline_acc: 0.5055\n",
      "Epoch 22/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.7191 - channel_loss: 0.7191 - baseline_loss: 0.7087 - channel_acc: 0.5610 - baseline_acc: 0.5609 - val_loss: 0.7767 - val_channel_loss: 0.7767 - val_baseline_loss: 0.7716 - val_channel_acc: 0.4955 - val_baseline_acc: 0.4958\n",
      "Epoch 23/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.7153 - channel_loss: 0.7153 - baseline_loss: 0.7058 - channel_acc: 0.5631 - baseline_acc: 0.5632 - val_loss: 0.7707 - val_channel_loss: 0.7707 - val_baseline_loss: 0.7686 - val_channel_acc: 0.5163 - val_baseline_acc: 0.5163\n",
      "Epoch 24/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.7130 - channel_loss: 0.7130 - baseline_loss: 0.7047 - channel_acc: 0.5657 - baseline_acc: 0.5656 - val_loss: 0.7752 - val_channel_loss: 0.7752 - val_baseline_loss: 0.7735 - val_channel_acc: 0.5047 - val_baseline_acc: 0.5043\n",
      "Epoch 25/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.7132 - channel_loss: 0.7132 - baseline_loss: 0.7054 - channel_acc: 0.5659 - baseline_acc: 0.5660 - val_loss: 0.7705 - val_channel_loss: 0.7705 - val_baseline_loss: 0.7689 - val_channel_acc: 0.5067 - val_baseline_acc: 0.5065\n",
      "Epoch 26/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.7097 - channel_loss: 0.7097 - baseline_loss: 0.7028 - channel_acc: 0.5663 - baseline_acc: 0.5664 - val_loss: 0.7667 - val_channel_loss: 0.7667 - val_baseline_loss: 0.7642 - val_channel_acc: 0.5123 - val_baseline_acc: 0.5117\n",
      "Epoch 27/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.7064 - channel_loss: 0.7064 - baseline_loss: 0.7003 - channel_acc: 0.5685 - baseline_acc: 0.5686 - val_loss: 0.7707 - val_channel_loss: 0.7707 - val_baseline_loss: 0.7712 - val_channel_acc: 0.4985 - val_baseline_acc: 0.4985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/40\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.7031 - channel_loss: 0.7031 - baseline_loss: 0.6975 - channel_acc: 0.5733 - baseline_acc: 0.5734 - val_loss: 0.7682 - val_channel_loss: 0.7682 - val_baseline_loss: 0.7676 - val_channel_acc: 0.5105 - val_baseline_acc: 0.5103\n",
      "Epoch 29/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.7018 - channel_loss: 0.7018 - baseline_loss: 0.6967 - channel_acc: 0.5732 - baseline_acc: 0.5731 - val_loss: 0.7734 - val_channel_loss: 0.7734 - val_baseline_loss: 0.7760 - val_channel_acc: 0.5108 - val_baseline_acc: 0.5107\n",
      "Epoch 30/40\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.7004 - channel_loss: 0.7004 - baseline_loss: 0.6959 - channel_acc: 0.5732 - baseline_acc: 0.5732 - val_loss: 0.7691 - val_channel_loss: 0.7691 - val_baseline_loss: 0.7705 - val_channel_acc: 0.5110 - val_baseline_acc: 0.5108\n",
      "Epoch 00030: early stopping\n"
     ]
    }
   ],
   "source": [
    "train_res = simple_model.fit(X_train_train,\n",
    "                      [y_train_train,y_train_train],\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=verbose,\n",
    "                      validation_data=(X_train_val,\n",
    "                                       [y_train_val,y_train_val]),\n",
    "                      callbacks=\n",
    "                      [EarlyStopping(patience=patience,mode='min',verbose=verbose)]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_acc': 0.76880000000000004,\n",
       " 'baseline_loss': 0.69733354682922366,\n",
       " 'channel_acc': 0.76819999999999999,\n",
       " 'channel_loss': 0.69576388959884639,\n",
       " 'loss': 0.69576388959884639}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(simple_model,y_test=[y_test,y_test])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
